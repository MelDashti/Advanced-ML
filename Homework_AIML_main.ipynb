{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Kk0rtAlnSlDF",
        "jiwWzjzSio-h",
        "g1GznJhObXPk",
        "Sy4KrHClbAmC",
        "UPwkOR8taVdN",
        "Ru8vllrMbgvL",
        "z0MWgLingzhw",
        "lrLs_T2Qd0kc",
        "Gr9BxL8zeBfv"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MelDashti/Advanced-ML/blob/master/Homework_AIML_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf3z5SqWZ91b"
      },
      "source": [
        "# Torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbtEmI1AiTkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a0332a-05ea-4741-fc76-e611038a6db7"
      },
      "source": [
        "!pip3 install 'tqdm'\n",
        "!pip3 install \"colorama\"\n",
        "\n",
        "import torch\n",
        "#use GPU if available\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #'cpu' # 'cuda' or 'cpu'\n",
        "print(DEVICE)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9CGoasmZF8W",
        "outputId": "b6b1a382-f660-4fed-ed10-286e3a2a8e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjvnq3FjBmh"
      },
      "source": [
        "# Download Dataset GTEA61"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_InBE9GCpATe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "e75b2f26-caf1-45ab-b515-c00d34a8a0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'drive' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3b8a479202a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'drive' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGOhXMNqjMed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b309b0e-e200-4d67-a31b-88be3d8bd45b"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "import sys, os\n",
        "\n",
        "#1YKfdhB9Xxh4pmND1V3gcm3Gyjc8v8idq\n",
        "if not os.path.isfile('/content/GTEA61.zip'):\n",
        "  !gdown --id 1Z5RWA8yKIy0PvxMlScV-aAz22ITtivfk # 3-5 min\n",
        "  !jar xvf  \"/content/GTEA61.zip\"\n",
        "\n",
        "if not os.path.isdir('/content/GTEA61'):\n",
        "  print(\"Dataset doesn't exist\")\n",
        "\n",
        "#Weights\n",
        "if not os.path.isfile(\"/content/best_model_state_dict_rgb_split2.pth\"):\n",
        "  !gdown --id 1B7Xh6hQ9Py8fmL-pjmLzlCent6dnuex5 # 3-5 min\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Z5RWA8yKIy0PvxMlScV-aAz22ITtivfk\n",
            "From (redirected): https://drive.google.com/uc?id=1Z5RWA8yKIy0PvxMlScV-aAz22ITtivfk&confirm=t&uuid=9a2fe9d6-e608-459f-ae77-80f4feef22fe\n",
            "To: /content/GTEA61.zip\n",
            "  6% 251M/4.56G [00:08<01:12, 59.0MB/s]Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/gdown\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gdown/__main__.py\", line 172, in main\n",
            "    download(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gdown/download.py\", line 368, in download\n",
            "    for chunk in res.iter_content(chunk_size=CHUNK_SIZE):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 820, in generate\n",
            "    yield from self.raw.stream(chunk_size, decode_content=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 1060, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 949, in read\n",
            "    data = self._raw_read(amt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 873, in _raw_read\n",
            "    data = self._fp_read(amt, read1=read1) if not fp_closed else b\"\"\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 856, in _fp_read\n",
            "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 466, in read\n",
            "    s = self.fp.read(amt)\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1303, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1159, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "KeyboardInterrupt\n",
            "  6% 252M/4.56G [00:08<02:33, 28.1MB/s]\n",
            "^C\n",
            "java.io.FileNotFoundException: /content/GTEA61.zip (No such file or directory)\n",
            "\tat java.base/java.io.FileInputStream.open0(Native Method)\n",
            "\tat java.base/java.io.FileInputStream.open(FileInputStream.java:219)\n",
            "\tat java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)\n",
            "\tat java.base/java.io.FileInputStream.<init>(FileInputStream.java:112)\n",
            "\tat jdk.jartool/sun.tools.jar.Main.run(Main.java:413)\n",
            "\tat jdk.jartool/sun.tools.jar.Main.main(Main.java:1686)\n",
            "Dataset doesn't exist\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1B7Xh6hQ9Py8fmL-pjmLzlCent6dnuex5\n",
            "From (redirected): https://drive.google.com/uc?id=1B7Xh6hQ9Py8fmL-pjmLzlCent6dnuex5&confirm=t&uuid=94543de3-7f71-4497-b271-7014484dd570\n",
            "To: /content/best_model_state_dict_rgb_split2.pth\n",
            "100% 163M/163M [00:05<00:00, 31.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "iZdILrO9oeH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk0rtAlnSlDF"
      },
      "source": [
        "\n",
        "# Download Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8xcWfReaSd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b70da0d-9bca-4f9a-ed41-917036477842"
      },
      "source": [
        "!git clone \"https://github.com/plana93/Homework_AIML.git\"\n",
        "#!rm -r \"/content/Homework_AIML\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Homework_AIML'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Total 78 (delta 0), reused 0 (delta 0), pack-reused 78 (from 1)\u001b[K\n",
            "Receiving objects: 100% (78/78), 734.41 KiB | 2.55 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwWzjzSio-h"
      },
      "source": [
        "\n",
        "\n",
        "# Import Code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl6fSd3MXofW"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.backends import cudnn\n",
        "import torchvision\n",
        "from colorama import init\n",
        "from colorama import Fore, Back, Style\n",
        "\n",
        "from torchvision.models import resnet34\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/Homework_AIML/\")\n",
        "import Homework_AIML\n",
        "from Homework_AIML import *\n",
        "\n",
        "from gtea_dataset import GTEA61, GTEA61_flow, GTEA61_2Stream\n",
        "from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n",
        "                                RandomHorizontalFlip)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1GznJhObXPk"
      },
      "source": [
        "#**Learning without Temporal information** (avgpool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy4KrHClbAmC"
      },
      "source": [
        "#MAIN PARAMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-tz9mHPbCYW"
      },
      "source": [
        "homework_step = 0 #--> Learning without Temporal information (avgpool)\n",
        "#homework_step = 1 #--> Learning with Temporal information (LSTM)\n",
        "#homework_step = 2 #--> Learning with Spatio-Temporal information (ConvLSTM)\n",
        "\n",
        "\n",
        "\n",
        "DATA_DIR = '/content/Homework_AIML/GTEA61/' #path dataset\n",
        "model_folder = '/content/saved_models/' + \"/\" + \"homework_step\"+ str(homework_step) + \"/\" #path to save model\n",
        "if not os.path.isdir(model_folder):\n",
        "    os.makedirs(model_folder)\n",
        "\n",
        "\n",
        "# All this param can be change!\n",
        "\n",
        "NUM_CLASSES = 61\n",
        "BATCH_SIZE = 64\n",
        "LR = 0.001            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 4e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 200     # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = [25, 75, 150] # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "MEM_SIZE = 512       # Dim of internal state of LSTM or ConvLSTM\n",
        "SEQ_LEN = 3          # Num Frames\n",
        "\n",
        "# this dictionary is needed for the logger class\n",
        "parameters = {'DEVICE':DEVICE, 'NUM_CLASSES':NUM_CLASSES, 'BATCH_SIZE':BATCH_SIZE,\n",
        "             'LR':LR, 'MOMENTUM':MOMENTUM, 'WEIGHT_DECAY':WEIGHT_DECAY, 'NUM_EPOCHS':NUM_EPOCHS,\n",
        "             'STEP_SIZE':STEP_SIZE, 'GAMMA':GAMMA, 'MEM_SIZE':MEM_SIZE, 'SEQ_LEN':SEQ_LEN}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPwkOR8taVdN"
      },
      "source": [
        "#Dataloaders & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmxnQXSYaeWv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT_Gy79SgBLq"
      },
      "source": [
        "# Normalize\n",
        "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "spatial_transform = Compose([Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224),\n",
        "                             ToTensor(), normalize])\n",
        "spatial_transform_val = Compose([Scale(256), CenterCrop(224), ToTensor(), normalize])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "T69vfGGhjKa_",
        "outputId": "c17a1a36-6291-4f4d-98f5-34c31ba6ed9c"
      },
      "source": [
        "# Prepare Pytorch train/test Datasets\n",
        "train_dataset = GTEA61(DATA_DIR, split='train', transform=spatial_transform, seq_len=SEQ_LEN)\n",
        "test_dataset = GTEA61(DATA_DIR, split='test', transform=spatial_transform_val, seq_len=SEQ_LEN)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Train Dataset: {}'.format(len(train_dataset)))\n",
        "print('Test Dataset: {}'.format(len(test_dataset)))\n",
        "\n",
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['S2', 'S1', 'S3', 'S4']\n",
            "['S2', 'S1', 'S3', 'S4']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Homework_AIML/GTEA61/processed_frames2/S2/close_chocolate/1/rgb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-0696d9ba587b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Prepare Pytorch train/test Datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGTEA61\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspatial_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQ_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGTEA61\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspatial_transform_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQ_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Check dataset sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Homework_AIML/gtea_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, seq_len, transform, target_transform, label_map, mmaps, mmaps_transform, static_frames)\u001b[0m\n\u001b[1;32m    141\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;31m# in frames its length in number of frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Homework_AIML/GTEA61/processed_frames2/S2/close_chocolate/1/rgb'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21wjiwvW-OPQ"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMWuE-4SHxoY"
      },
      "source": [
        "import torch\n",
        "import resnetMod\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "\n",
        "# LSTM\n",
        "class MyLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(MyLSTMCell, self).__init__()\n",
        "\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        if state is None:\n",
        "            state = (Variable(torch.randn(x.size(0), x.size(1)).cuda()),\n",
        "                     Variable(torch.randn(x.size(0), x.size(1)).cuda()))\n",
        "\n",
        "\n",
        "\n",
        "        ##################################\n",
        "        # You should implement this part #\n",
        "        ##################################\n",
        "\n",
        "        return  None, None\n",
        "\n",
        "\n",
        "#ConvLSTM\n",
        "class MyConvLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, kernel_size=3, stride=1, padding=1):\n",
        "        super(MyConvLSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.conv_i_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_i_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.conv_f_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_f_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.conv_c_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_c_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.conv_o_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_o_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_i_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_i_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_i_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_f_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_f_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_f_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_c_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_c_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_c_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_o_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_o_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_o_hh.weight)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        if state is None:\n",
        "            state = (Variable(torch.randn(x.size(0), x.size(1), x.size(2), x.size(3)).cuda()),\n",
        "                     Variable(torch.randn(x.size(0), x.size(1), x.size(2), x.size(3)).cuda()))\n",
        "\n",
        "        ##################################\n",
        "        # You should implement this part #\n",
        "        ##################################\n",
        "\n",
        "        return  None, None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Network\n",
        "class ourModel(nn.Module):\n",
        "    def __init__(self, num_classes=61, mem_size=512, homework_step = 0 , DEVICE=\"\"):\n",
        "        super(ourModel, self).__init__()\n",
        "        self.DEVICE = DEVICE\n",
        "        self.num_classes = num_classes\n",
        "        self.resNet = resnetMod.resnet34(True, True)\n",
        "        self.mem_size = mem_size\n",
        "        self.weight_softmax = self.resNet.fc.weight\n",
        "        self.homework_step = homework_step\n",
        "        if self.homework_step == 1:\n",
        "          self.lstm_cell = MyLSTMCell(512, mem_size)\n",
        "        elif self.homework_step == 2:\n",
        "          self.lstm_cell = MyConvLSTMCell(512, mem_size)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.fc = nn.Linear(mem_size, self.num_classes)\n",
        "        self.classifier = nn.Sequential(self.dropout, self.fc)\n",
        "\n",
        "    def forward(self, inputVariable):\n",
        "        #Learning without Temporal information (mean)\n",
        "        if self.homework_step == 0:\n",
        "            video_level_features = torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE)\n",
        "            for t in range(inputVariable.size(0)):\n",
        "                #spatial_frame_feat: (bs, 512, 7, 7)\n",
        "                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n",
        "                #frames_feat: (bs, 512)\n",
        "                frame_feat = self.avgpool(spatial_frame_feat).view(spatial_frame_feat.size(0), -1)\n",
        "                video_level_features = video_level_features + frame_feat\n",
        "\n",
        "            video_level_features = video_level_features / inputVariable.size(0)\n",
        "            logits = self.classifier(video_level_features)\n",
        "            return logits, video_level_features\n",
        "\n",
        "        #Learning with Temporal information (LSTM)\n",
        "        elif self.homework_step == 1:\n",
        "            state = ( torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE),\n",
        "                     torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE) )\n",
        "            for t in range(inputVariable.size(0)):\n",
        "                #spatial_frame_feat: (bs, 512, 7, 7)\n",
        "                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n",
        "                #frames_feat: (bs, 512)\n",
        "                frame_feat = self.avgpool(spatial_frame_feat).view(state[1].size(0), -1)\n",
        "                state = self.lstm_cell(frame_feat, state)\n",
        "\n",
        "            video_level_features = state[1]\n",
        "            logits = self.classifier(video_level_features)\n",
        "            return logits, video_level_features\n",
        "\n",
        "        #Learning with Temporal information (ConvLSTM)\n",
        "        elif self.homework_step == 2:\n",
        "            state = (torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).to(self.DEVICE),\n",
        "                     torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).to(self.DEVICE))\n",
        "            for t in range(inputVariable.size(0)):\n",
        "                #spatial_frame_feat: (bs, 512, 7, 7)\n",
        "                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n",
        "                state = self.lstm_cell(spatial_frame_feat, state)\n",
        "            video_level_features = self.avgpool(state[1]).view(state[1].size(0), -1)\n",
        "            logits = self.classifier(video_level_features)\n",
        "            return logits, video_level_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru8vllrMbgvL"
      },
      "source": [
        "#Build Model - Loss - Opt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZe-ZbEL7z3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55df2ed2-4c98-45ec-82cd-6072f4c45164"
      },
      "source": [
        "#CUDA_LAUNCH_BLOCKING=1\n",
        "validate = True\n",
        "\n",
        "model = ourModel(num_classes=NUM_CLASSES, mem_size=MEM_SIZE, homework_step=homework_step, DEVICE=DEVICE) #model\n",
        "\n",
        "#Train only the lstm cell and classifier\n",
        "model.train(False)\n",
        "for params in model.parameters():\n",
        "    params.requires_grad = False\n",
        "\n",
        "if homework_step > 0:\n",
        "    for params in model.lstm_cell.parameters():\n",
        "        params.requires_grad = True\n",
        "    model.lstm_cell.train(True)\n",
        "\n",
        "for params in model.classifier.parameters():\n",
        "    params.requires_grad = True\n",
        "model.classifier.train(True)\n",
        "\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "#model.load_state_dict(torch.load(\"/content/best_model_state_dict_rgb_split2.pth\", map_location=torch.device('cpu')), strict=True)\n",
        "\n",
        "\n",
        "#Loss\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#Opt\n",
        "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer_fn = optim.Adam(trainable_params, lr=LR, weight_decay=WEIGHT_DECAY, eps=1e-4)\n",
        "#Scheduler\n",
        "optim_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=STEP_SIZE, gamma=GAMMA)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 211MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0MWgLingzhw"
      },
      "source": [
        "#Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-uE2A9eHmtn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "f5a1af28-60a4-47e4-8ccc-ee3ab2d0d862"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "train_iter = 0\n",
        "val_iter = 0\n",
        "min_accuracy = 0\n",
        "\n",
        "trainSamples = len(train_dataset) - (len(train_dataset) % BATCH_SIZE)\n",
        "val_samples = len(test_dataset)\n",
        "iterPerEpoch = len(train_loader)\n",
        "val_steps = len(val_loader)\n",
        "cudnn.benchmark\n",
        "model_checkpoint = \"model\" #name\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    numCorrTrain = 0\n",
        "\n",
        "    #blocks to train\n",
        "    if homework_step > 0:\n",
        "        model.lstm_cell.train(True)\n",
        "    model.classifier.train(True)\n",
        "\n",
        "\n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "        train_iter += 1\n",
        "        optimizer_fn.zero_grad()\n",
        "\n",
        "        # (BS, Frames, C, W, H) --> (Frames, BS, C, W, H)\n",
        "        inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "        labelVariable = targets.to(DEVICE)\n",
        "\n",
        "        # feeds in model\n",
        "        output_label, _ = model(inputVariable)\n",
        "\n",
        "        # compute loss\n",
        "        loss = loss_fn(output_label, labelVariable)\n",
        "\n",
        "        # backward loss and optimizer step\n",
        "        loss.backward()\n",
        "        optimizer_fn.step()\n",
        "\n",
        "        #compute the training accuracy\n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorrTrain += torch.sum(predicted == labelVariable.data).data.item()\n",
        "        step_loss = loss.data.item()\n",
        "        epoch_loss += step_loss\n",
        "\n",
        "    avg_loss = epoch_loss/iterPerEpoch\n",
        "    trainAccuracy = (numCorrTrain / trainSamples) * 100\n",
        "    #train_logger.add_epoch_data(epoch+1, trainAccuracy, avg_loss)\n",
        "    print(Fore.BLACK + 'Train: Epoch = {} | Loss = {:.3f} | Accuracy = {:.3f}'.format(epoch+1, avg_loss, trainAccuracy))\n",
        "    if validate:\n",
        "        if (epoch+1) % 1 == 0:\n",
        "            model.train(False)\n",
        "            val_loss_epoch = 0\n",
        "            numCorr = 0\n",
        "            for j, (inputs, targets) in enumerate(val_loader):\n",
        "                val_iter += 1\n",
        "                inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "                labelVariable = targets.to(DEVICE)\n",
        "\n",
        "                output_label, _ = model(inputVariable)\n",
        "                val_loss = loss_fn(output_label, labelVariable)\n",
        "                val_loss_step = val_loss.data.item()\n",
        "                val_loss_epoch += val_loss_step\n",
        "                _, predicted = torch.max(output_label.data, 1)\n",
        "                numCorr += torch.sum(predicted == labelVariable.data).data.item()\n",
        "                #val_logger.add_step_data(val_iter, numCorr, val_loss_step)\n",
        "\n",
        "            val_accuracy = (numCorr / val_samples) * 100\n",
        "            avg_val_loss = val_loss_epoch / val_steps\n",
        "\n",
        "            print(Fore.GREEN + 'Val: Epoch = {} | Loss {:.3f} | Accuracy = {:.3f}'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
        "            if val_accuracy > min_accuracy:\n",
        "                print(\"[||| NEW BEST on val||||]\")\n",
        "                save_path_model = os.path.join(model_folder, model_checkpoint)\n",
        "                torch.save(model.state_dict(), save_path_model)\n",
        "                min_accuracy = val_accuracy\n",
        "\n",
        "    optim_scheduler.step()\n",
        "\n",
        "print(Fore.CYAN + \"Best Acc --> \", min_accuracy)\n",
        "print(Fore.CYAN + \"Last Acc --> \", val_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c39e008d1339>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmin_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainSamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mval_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0miterPerEpoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrLs_T2Qd0kc"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqK1ExB0cl8D"
      },
      "source": [
        "model.train(False)\n",
        "val_loss_epoch = 0\n",
        "numCorr = 0\n",
        "val_iter = 0\n",
        "val_samples = len(test_dataset)\n",
        "val_steps = len(val_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for j, (inputs, targets) in enumerate(val_loader):\n",
        "        val_iter += 1\n",
        "        inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "        labelVariable = targets.to(DEVICE)\n",
        "\n",
        "        output_label, _ = model(inputVariable)\n",
        "        val_loss = loss_fn(output_label, labelVariable)\n",
        "        val_loss_step = val_loss.data.item()\n",
        "        val_loss_epoch += val_loss_step\n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorr += torch.sum(predicted == labelVariable.data).data.item()\n",
        "\n",
        "    val_accuracy = (numCorr / val_samples) * 100\n",
        "    avg_val_loss = val_loss_epoch / val_steps\n",
        "\n",
        "print('Loss {:.3f} | Accuracy = {:.3f}'.format(avg_val_loss, val_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr9BxL8zeBfv"
      },
      "source": [
        "#**Learning with Temporal information** (LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-qHYgnyf_wn"
      },
      "source": [
        "#**Learning with Spatio-Temporal information** (ConvLSTM)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}